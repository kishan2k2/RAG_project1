{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import retrieval_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Assets/Data/books_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genre</th>\n",
       "      <th>SubGenre</th>\n",
       "      <th>Height</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fundamentals of Wavelets</td>\n",
       "      <td>Goswami, Jaideva</td>\n",
       "      <td>tech</td>\n",
       "      <td>signal_processing</td>\n",
       "      <td>228</td>\n",
       "      <td>Wiley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Smart</td>\n",
       "      <td>Foreman, John</td>\n",
       "      <td>tech</td>\n",
       "      <td>data_science</td>\n",
       "      <td>235</td>\n",
       "      <td>Wiley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>God Created the Integers</td>\n",
       "      <td>Hawking, Stephen</td>\n",
       "      <td>tech</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>197</td>\n",
       "      <td>Penguin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Superfreakonomics</td>\n",
       "      <td>Dubner, Stephen</td>\n",
       "      <td>science</td>\n",
       "      <td>economics</td>\n",
       "      <td>179</td>\n",
       "      <td>HarperCollins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orientalism</td>\n",
       "      <td>Said, Edward</td>\n",
       "      <td>nonfiction</td>\n",
       "      <td>history</td>\n",
       "      <td>197</td>\n",
       "      <td>Penguin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Title            Author       Genre           SubGenre  \\\n",
       "0  Fundamentals of Wavelets  Goswami, Jaideva        tech  signal_processing   \n",
       "1                Data Smart     Foreman, John        tech       data_science   \n",
       "2  God Created the Integers  Hawking, Stephen        tech        mathematics   \n",
       "3         Superfreakonomics   Dubner, Stephen     science          economics   \n",
       "4               Orientalism      Said, Edward  nonfiction            history   \n",
       "\n",
       "   Height      Publisher  \n",
       "0     228          Wiley  \n",
       "1     235          Wiley  \n",
       "2     197        Penguin  \n",
       "3     179  HarperCollins  \n",
       "4     197        Penguin  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=\"./Assets/Data/books_new.csv\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "textSplitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 150)\n",
    "docs = textSplitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "model_kwargs = {'device':'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings':False}\n",
    "embedding = HuggingFaceEmbeddings(model_name = modelPath, \n",
    "                                  model_kwargs = model_kwargs, \n",
    "                                  encode_kwargs = encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db39de23ec041998b3085a724e48f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = AutoTokenizer.from_pretrained(\"google/gemma-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1e00b86456448e926a1c117fbab171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3910053064b846028a19e03a086ea440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a2cc25557244aa94ca50867a9abddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63524eb0761c457da2341eef629110df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b52bcda60440bbab94207ec4ae1cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc53659e868e4983bd7c0b06c8f8b56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA enabled? False\n"
     ]
    }
   ],
   "source": [
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", \n",
    "                model = model, \n",
    "                tokenizer=tokenize, \n",
    "                return_tensors = 'pt', \n",
    "                max_length = 512, \n",
    "                max_new_tokens = 512, \n",
    "                model_kwargs={\"torch_dtype\": torch.bfloat16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(\n",
    " pipeline=pipe,\n",
    " model_kwargs={\"temperature\": 0.7, \"max_length\": 512},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    " llm=llm,\n",
    " chain_type=\"stuff\",\n",
    " retriever=db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Title: Data Scientists at Work\\nAuthor: Sebastian Gutierrez\\nGenre: tech\\nSubGenre: data_science\\nHeight: 230\\nPublisher: Apress' metadata={'source': './Assets/Data/books_new.csv', 'row': 10}\n"
     ]
    }
   ],
   "source": [
    "# Suppose you have the index of the document in the FAISS index\n",
    "faiss_index = 10\n",
    "\n",
    "# Get the ID of the document in the docstore\n",
    "doc_id = db.index_to_docstore_id[faiss_index]\n",
    "\n",
    "# Retrieve the document from the docstore\n",
    "document = db.docstore.search(doc_id)\n",
    "\n",
    "# Now you have the document\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HuggingFaceEmbeddings' object has no attribute 'encode_sentence'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m query_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuggest me some tech books\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get embedding for the query sentence\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_sentence\u001b[49m([query_sentence])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Perform a similarity search in the FAISS index\u001b[39;00m\n\u001b[0;32m      8\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Number of nearest neighbors to retrieve\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HuggingFaceEmbeddings' object has no attribute 'encode_sentence'"
     ]
    }
   ],
   "source": [
    "# New sentence to query\n",
    "query_sentence = \"Suggest me some tech books\"\n",
    "\n",
    "# Get embedding for the query sentence\n",
    "query_embedding = embedding.encode_sentence([query_sentence])\n",
    "\n",
    "# Perform a similarity search in the FAISS index\n",
    "k = 1  # Number of nearest neighbors to retrieve\n",
    "distances, indices = db.search(query_embedding, k)\n",
    "\n",
    "# Get the nearest neighbor's index and corresponding text\n",
    "nearest_neighbor_index = indices[0][0]\n",
    "nearest_neighbor_text = docs[nearest_neighbor_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "hf_token = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_url = f\"https://api-inference.huggingface.co/pipeline/feature-extraction/{model_id}\"\n",
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(texts):\n",
    "    response = requests.post(api_url, headers=headers, json={\"inputs\": texts, \"options\":{\"wait_for_model\":True}})\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"How do I get a replacement Medicare card?\",\n",
    "        \"What is the monthly premium for Medicare Part B?\",\n",
    "        \"How do I terminate my Medicare Part B (medical insurance)?\",\n",
    "        \"How do I sign up for Medicare?\",\n",
    "        \"Can I sign up for Medicare Part B if I am working and have health insurance through an employer?\",\n",
    "        \"How do I sign up for Medicare Part B if I already have Part A?\",\n",
    "        \"What are Medicare late enrollment penalties?\",\n",
    "        \"What is Medicare and who can get it?\",\n",
    "        \"How can I get help with my Medicare Part A and Part B premiums?\",\n",
    "        \"What are the different parts of Medicare?\",\n",
    "        \"Will my Medicare premiums be higher because of my higher income?\",\n",
    "        \"What is TRICARE ?\",\n",
    "        \"Should I sign up for Medicare Part B if I have Veterans' Benefits?\"]\n",
    "\n",
    "output = query(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Suggest me some good tech books\"\n",
    "output = query(question)\n",
    "\n",
    "query_embeddings = torch.FloatTensor(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "search_type of 1 not allowed. Expected search_type to be 'similarity' or 'mmr'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Number of nearest neighbors to retrieve\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m distances, indices \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get the nearest neighbor's index and corresponding text\u001b[39;00m\n\u001b[0;32m      5\u001b[0m nearest_neighbor_index \u001b[38;5;241m=\u001b[39m indices[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mm:\\Third Year\\Sixth Semester\\Projects\\RAG_project1\\venv\\Lib\\site-packages\\langchain_core\\vectorstores.py:163\u001b[0m, in \u001b[0;36mVectorStore.search\u001b[1;34m(self, query, search_type, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_marginal_relevance_search(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_type of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not allowed. Expected \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_type to be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmmr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: search_type of 1 not allowed. Expected search_type to be 'similarity' or 'mmr'."
     ]
    }
   ],
   "source": [
    "k = 1  # Number of nearest neighbors to retrieve\n",
    "distances, indices = db.search(output, k)\n",
    "\n",
    "# Get the nearest neighbor's index and corresponding text\n",
    "nearest_neighbor_index = indices[0][0]\n",
    "nearest_neighbor_text = docs[nearest_neighbor_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
